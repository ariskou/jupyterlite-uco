{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5344fa45",
   "metadata": {},
   "source": [
    "# Project01 for L2 - Informatique\n",
    "\n",
    "*In this project, you will be cleaning, analysing and visualising datasets recording stock prices.*\n",
    "\n",
    "__**Date and time of submission: Tuesday 2023-04-18 at 20:00 in the evening. There is a 40% penalty for missing the deadline.**__\n",
    "\n",
    "The commands to load the datasets into Pandas dataframes have been written for you, but you will still need to do all the other steps.\n",
    "\n",
    "This notebook is written in a step-by-step manner, but you are free to modify it to suit your needs.\n",
    "\n",
    "Note that there are three different sets of data, each of which is fairly large.\n",
    "\n",
    "You are **strongly** encouraged to work on a small subset of the datasets first, and once you are satisfied that everything is working well, load a larger portion of the datasets, and eventually work on the entire datasets.\n",
    "\n",
    "Another thing to bear in mind is that the three datasets are **very similar**: they have the same columns and the same number of rows. However, the values in the data sets are different, although they are **correlated**, as will be explained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652c6b7",
   "metadata": {},
   "source": [
    "*Execute the following cell, you do not need to understand it, it just loads the appropriate packages so that you can work with the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "%pip install pandas-datareader\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(\"Data file found:\", os.path.join(dirname, filename))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame\n",
    "from random import Random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9558b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Loading the dataset\n",
    "\n",
    "In the next cell you can configure what percentage of the data set to load (1%, 10%, 100%). Start with a small amount, e.g. 1%, to test your solutions and then gradually increase it (10%, 100%) to test larger parts of the dataset.\n",
    "\n",
    "*Remember that you will need to come back here and re-execute all the cell when you want to change the percentage of the datasets used*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressed as a percentage (1, 10, or 100)\n",
    "dataset_percentage = 1\n",
    "# dataset_percentage = 10\n",
    "# dataset_percentage = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c32b0",
   "metadata": {},
   "source": [
    "This will actually load all three datasets, for the stocks named Apple, Pear and Orange, into the Pandas data frames named `dfapple`, `dfpear` and `dforange` correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfapple = pd.read_pickle(f\"data/Apple_{dataset_percentage}pct.pickle.gz\")\n",
    "dfpear = pd.read_pickle(f\"data/Pear_{dataset_percentage}pct.pickle.gz\")\n",
    "dforange = pd.read_pickle(f\"data/Orange_{dataset_percentage}pct.pickle.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d148e",
   "metadata": {},
   "source": [
    "Here we print the descriptions of each of these data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"dfapple:\", dfapple.describe())\n",
    "display(\"dfpear:\", dfpear.describe())\n",
    "display(\"dforange:\", dforange.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf515e3",
   "metadata": {},
   "source": [
    "Finally, here we print the `head()` of the `dfapple` data frame. You can do the same for the rest of the dataframes if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfapple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2236d1",
   "metadata": {},
   "source": [
    "# Project Assignment 1\n",
    "\n",
    "The data in each of the data frames is corrupted. You need to pre-process (or clean) the data, making sure that a number of conditions are all met after the data has been processed in order for it to be considered \"clean\".\n",
    "\n",
    "Start working on `dfapple` and once you have implemented the cleaning/pre-processing, do the same for the other two dataframes.\n",
    "\n",
    "## Conditions to meet\n",
    "\n",
    "### Condition 1 - Negative values\n",
    "Data quality issue: Some records in the dataset have **negative** values that do not make sense. Specifically, the following columns are affected:\n",
    "\n",
    "* `open`\n",
    "* `close`\n",
    "* `high`\n",
    "* `low`\n",
    "* `volume`\n",
    "\n",
    "These columns must always have values that are **never negative**.\n",
    "\n",
    "You need to *filter* the data set and *remove all rows* where *any* of the preceding columns have a negative value.\n",
    "\n",
    "Put another way, you can *filter* the data set and *keep only the rows* where *none* of the preceding columns has a negative value.\n",
    "\n",
    "### Condition 2 - abnormally high values\n",
    "Data quality issue: some records in the data set have **abnormally high** positive values that make no sense. Specifically, the following columns are affected:\n",
    "\n",
    "* `open`\n",
    "* `close`\n",
    "* `high`\n",
    "* `low`\n",
    "\n",
    "These columns must always have values that are **never abnormally high**.\n",
    "\n",
    "*Abnormally high is interpreted to mean more than 100 times the average value of the column. For example, if the average of the `open` column is `10`, then any value above `100*10=1000` should be considered abnormally high.\n",
    "\n",
    "You need to *filter* the data set and *remove* all the rows where *any* of the previous columns has an *abnormally high* value.\n",
    "\n",
    "In other words, you can *filter* the data set and *keep only the rows* where *none* of the preceding columns has an *abnormally high* value.\n",
    "\n",
    "### Condition 3 - Zero values\n",
    "\n",
    "Data quality issue: Some records in the dataset have **zero values** which do not make sense. Specifically, the following columns are affected\n",
    "\n",
    "* `open`\n",
    "* `close`\n",
    "* `high`\n",
    "* `low`\n",
    "\n",
    "These columns must always have values that are *never zero*.\n",
    "\n",
    "You need to *filter* the data set and *remove all rows* where *any* of the preceding columns have a value of zero.\n",
    "\n",
    "Put another way, you can *filter* the data set and *keep only the rows* where *none* of the preceding columns has a value of zero.\n",
    "\n",
    "### Condition 4 - High/Low Values\n",
    "\n",
    "Data quality issue: some records in the data set have **`high`** or **`low`** values that do not make sense. Specifically, the following columns are affected\n",
    "\n",
    "* `high`\n",
    "* `low`\n",
    "\n",
    "These columns must always have values that are **always greater than or equal to each other**. More specifically, *in all rows*, the value of the column `high` **greater than or equal** to the value of the `low` column.\n",
    "\n",
    "You need to *filter* the data set and *remove* all the rows where the value of the high column is less than the value of the low column.\n",
    "\n",
    "In other words, you can *filter* the data set and *keep only the rows* where the value of the column `high` is *greater than or equal* to the value of the column `low`.\n",
    "\n",
    "### Condition 5 - Open/Close values\n",
    "\n",
    "Data quality problem: Some entries in the dataset have **`open` or `close` values**, which do not make sense. More specifically, the following columns are concerned:\n",
    "\n",
    "* `open`\n",
    "* `close`\n",
    "\n",
    "These columns must always have values that are **inside of the range of the corresponding \\[`high` -- `low`\\] values**. More specifically, *in all rows*, the value of *both* columns `open` and `close` **must be larger or equal** to the value of the `low` column *and* **must be smaller or equal** to the value of the `high` column.\n",
    "\n",
    "For example, it is abnormal if a row has the following values: `low=10, high=15, open=13, close=16`. In this case, the `close` value is larger than the value of `high`.\n",
    "\n",
    "You must *filter* the dataset and *remove all the rows* where the values of the columns `open` or `close` is outside the `low`--`high` range values.\n",
    "\n",
    "Said another way, you can *filter* the dataset and *keep only the rows* where the values of the columns `open` or `close` is *inside* the `low`--`high` range values.\n",
    "\n",
    "### Condition 6 - Temporal order in rows\n",
    "Data quality problem: Some entries in the dataset are **in the wrong temporal order**, which does not make sense. More specifically, the following column is concerned:\n",
    "\n",
    "* `timestamp`\n",
    "\n",
    "This column must always have values that are **correct chronological order**. \n",
    "For example, if in one row the value of `timestamp` is `2017-01-10 13:9:00` and in the **next** row the value of `timestamp` is `2017-01-10 13:2:00`, then the last row is not in correct chronological order and you must remove it\n",
    "\n",
    "You must *filter* the dataset and *remove all the rows* where the value of the column `timestamp` in one row is **before** the value of the column `timestamp` in the **previous** row.\n",
    "\n",
    "Said another way, you can *filter* the dataset and *keep only the rows* where the value of the column `timestamp` in one row is **after** the value of the column `timestamp` in the **previous** row.\n",
    "\n",
    "\n",
    "#### Warm up\n",
    "Before starting with cleaning up the data, it will be useful if you have a small piece of code that prints the contents of a column that you are working on, to be able to visualise the changes in the data.\n",
    "\n",
    "For example: this is the visualisation of the `open` column in `dfapple` when 10% of the dataset is loaded:\n",
    "\n",
    "![](Apple_open.png)\n",
    "\n",
    "*Hint:* pass the parameter `ci=None` to the `sns.lineplot()` to significantly speed-up the drawing of the diagram.\n",
    "\n",
    "Your code should follow. At the end of your code, you should have `clean` data in the `dfapple`, `dfpear` and `dforange` data frames.\n",
    "\n",
    "In the following cells, use as many cells as you need (i.e., you can create new ones if you want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fd9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9aa753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4ac74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca21c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84ac4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202b803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e80df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fd974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fe106e2",
   "metadata": {},
   "source": [
    "# Project assignment 2\n",
    "\n",
    "After the clean-up of the data, your task is to do a very **simple price prediction model**.\n",
    "\n",
    "The values in all the columns in the three data sets are somehow related (but the exact way is unknown to you), so you need to investigate and try to find this relationship.\n",
    "\n",
    "Start as before with a part of the dataset `dfapple` and try to see the relationship between the values of one of the columns, e.g. `open`, in the `dfpear` dataset.\n",
    "\n",
    "You already know that the relationship is not exact (i.e. that there is some variability, which you can consider a tolerable prediction error).\n",
    "\n",
    "You also know that the relationship is time-invariant. That is, it does **not change over time**.\n",
    "\n",
    "The aim is that if you are given a values from one column from the `dfapple` dataset, you should be able to predict what the equivalent values of the `dfpear` and `dforange` values are.\n",
    "\n",
    "As a more specific example, imagine that:\n",
    "\n",
    "* at `2017-01-09 13:02:00` the value of `dforange` in the `open` column is 12 (dollars).\n",
    "* at the same moment in time in the value of `dfpear` in the `open` column is 10 (dollars).\n",
    "* Now, if the value of `dforange` in the `open` column at the next instant, e.g. at `2017-01-09 13:03:00`, the value is 13 (dollars):\n",
    "  * **try to predict what the value of `dfpear` in the `open` column will be.**\n",
    "\n",
    "*Hint:* Use the visualisation techniques to verify your predictions.\n",
    "*Hint:* Calculate the difference between your predicted value and the actual value (which is available) to see how well you are doing.\n",
    "\n",
    "The assessment for this exercise will also have a section at the end where a new set of data - unknown to you - will be provided and you will have to make the same prediction during the exam. To succeed in this task, you must make your prediction method **as general as possible**.\n",
    "\n",
    "The only information you have is that the overall relationship will be **of the same type**, but not necessarily of the same magnitude.\n",
    "\n",
    "## Explicit aims:\n",
    "\n",
    "1. Given values in `dfapple` of the columns `open`,`close`, `high`, `low` predict the value of the same column in `dfpear` **and** `dforange` at the same point in time.\n",
    "2. Given values in `dfapple` of the columns `open`,`close`, `high`, `low` and an unknown new dataset in a dataframe named `dfunknown`predict the value of the same column in `dfunknown` at the same point in time.\n",
    "  \n",
    "\n",
    "In the following cells, use as many cells as you need (i.e., you can create noew ones if you want).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83478206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348aead4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a52770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d81c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c764bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa5fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf6d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd9802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fde445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.605443,
   "end_time": "2022-04-07T01:58:36.669061",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-07T01:57:55.063618",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
