{
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Slideshow",
    "rise": {
      "scroll": true,
      "theme": "beige",
      "transition": "fade"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Essential Tools - Pandas\n\n_Adapted from https://github.com/mcrovella/CS506-Computational-Tools-for-Data-Science/blob/master/02B-Pandas.ipynb_",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "%pip install pandas-datareader",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%pip install requests",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%pip install scikit-learn",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Pandas is the Python Data Analysis Library. \n\nPandas is an extremely versatile tool for manipulating datasets.   \n\nIt also produces high quality plots with matplotlib, and integrates nicely with other libraries that expect NumPy arrays.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Use of Pandas is a data science __best practice.__",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The most important tool provided by Pandas is the **data frame.**\n\nA data frame is a table in which each row and column is given a label.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Pandas DataFrames are documented at:\n\nhttp://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html\n\nGet in the habit: whenever you load data, place it into a dataframe as your first step.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Getting started",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport pandas_datareader.data as web\nfrom pandas import Series, DataFrame\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime\n\n#pd.__version__\n\n%matplotlib inline",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Fetching, storing and retrieving your data",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "For demonstration purposes, we'll load the data directly from a stored file. The data is originally from Yahoo! Finance.",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# stocks = 'AAPL'\n# data_source = 'yahoo'\n# start = datetime(2021,1,1)\n# end = datetime(2021,12,31)\n\n# yahoo_stocks = web.DataReader(stocks, data_source, start, end)\n## let's write the dataframe out to a ``.csv`` file\n# yahoo_stocks.to_csv('yahoo_data.csv')\n",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# read a ``.csv`` file into a dataframe.   This is probably the most common way you will get data into Pandas.\ndf = pd.read_csv('yahoo_AAPL_data.csv')\ndf.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "This is a typical example of a dataframe.  \n\nNotice how each row has a label and each column has a label.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "A dataframe is an object that has __many__ methods associated with it, to do all sorts of useful things.\n\nHere is a simple method: ``.info()``",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.info()",
      "metadata": {
        "scrolled": true,
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Working with data columns",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "In general, we'll usually organize things so that rows in the dataframe are __items__ and columns are __features__.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.columns",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Pandas allows you to use standard python __indexing__ to refer to columns (eg features) in your dataframe:",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df['Open']",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Pandas also allows you to use a syntax like an object attribute to refer to a column.\n\nBut note that the column name cannot include a space in this case.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.Open",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "You can select a list of columns:",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df[['Open','Close']].head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Putting things together -- make sure this syntax is clear to you:",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.Date.head(10)",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.Date.tail(10)",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Changing column names is as simple as assigning to the ``.columns`` property.\n\nLet's adjust column names so that none of them include spaces:",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_column_names = [x.lower().replace(' ','_') for x in df.columns]\ndf.columns = new_column_names\ndf.info()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "(Be sure you understand the __list comprehension__ used above -- it's a common and important way to process a list in python.)",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now **all** columns can be accessed using the **dot** notation:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.adj_close.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## A sampling of DataFrame methods.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "A dataframe object has many useful methods.\n\nFamiliarize yourself with dataframe methods -- they are very useful.\n\nThese should be self-explanatory.",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df[['high', 'low', 'open', 'close', 'volume', 'adj_close']].mean()",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[['high', 'low', 'open', 'close', 'volume', 'adj_close']].std()",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[['high', 'low', 'open', 'close', 'volume', 'adj_close']].median()",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.open.mean()",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.high.mean()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Plotting methods\n\nPandas has an extensive library of plotting functions, and they are very easy to use.\n\nThese are your \"first look\" functions.\n\n(Later you will use specialized graphics packages for more sophisticated visualizations.)",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.high.plot(label='High')\ndf.low.plot(label='Low')\nplt.title('AAPL Stock Price')\nplt.ylabel('Dollars')\nplt.legend(loc='best');",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.adj_close.hist()\nplt.xlabel('Adjusted Closing Price')\nplt.ylabel('Dollars')\nplt.title('AAPL');",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Bulk Operations",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Methods like ``sum()`` and ``std()`` work on entire columns. \n\nWe can run our own functions across all values in a column (or row) using ``apply()``.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "As an example, let's go back to this plot:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.high.plot(label='High')\ndf.low.plot(label='Low')\nplt.title('AAPL Stock Price')\nplt.ylabel('Dollars')\nplt.legend(loc='best');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "It's __almost__ perfect.  The only problem is the $x$-axis: it should show time.\n\nTo fix this, we need to make the dataframe __index__ -- that is, the __row labels__ -- into dates.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "We have a problem however: the \"dates\" in our data are only __strings__.   We need Pandas to understand that they are actually dates.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df.date.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The **values** property of the column returns a list of values for the column. Inspecting the first value reveals that these are strings with a particular format.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "first_date = df.date.values[0]\nfirst_date",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To convert these strings to actual dates we'll use the ``datetime`` standard python package:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "datetime.strptime(first_date, \"%Y-%m-%d\")",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "And to do this for each string in the ``date`` column we will use ``.apply()``:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df = df.copy()\nnew_df.date = df.date.apply(lambda d: datetime.strptime(d, \"%Y-%m-%d\"))\nnew_df.date.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Each row in a DataFrame is associated with an index, which is a label that uniquely identifies a row.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The row indices so far have been auto-generated by pandas, and are simply integers starting from 0. \n\nFixing this is as easy as assigning to the `index` property of the DataFrame.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df.index = new_df.date\nnew_df.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now that we have made an index based on a real date, we can drop the original `date` column.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df = new_df.drop(['date'],axis=1)\nnew_df.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we can see that Pandas handles these dates quite nicely:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df.high.plot(label='High')\nnew_df.low.plot(label='Low')\nplt.title('AAPL Stock Price')\nplt.ylabel('Dollars')\nplt.legend(loc='best');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Accessing rows of the DataFrame\n\nSo far we've seen how to access a column of the DataFrame.  To access a row we use a different notation.\n\nTo access a row by its index value, use the **`.loc()`** method.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df.loc[datetime(2021,1,21,0,0)]",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To access a row by its sequence number (ie, like an array index), use **`.iloc()`** ('Integer Location')",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df.iloc[0,:]",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To iterate over the rows, use **`.iterrows()`**",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "num_positive_days = 0\nfor idx, row in df.iterrows():\n    if row.close > row.open:\n        num_positive_days += 1\n        \nprint(\"The total number of positive-gain days is {}.\".format(num_positive_days))",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Filtering",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "It is easy to select interesting rows from the data.  \n\nAll the operations below return a new DataFrame, which itself can be treated the same way as all DataFrames we have seen so far.",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "tmp_high = new_df.high > 150\ntmp_high.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Summing a Boolean array is the same as counting the number of **`True`** values.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "sum(tmp_high)",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's select only the rows of **`df1`** that correspond to **`tmp_high`**",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df[tmp_high]",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Putting it all together, we have the following commonly-used patterns:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "positive_days = new_df[new_df.close > new_df.open]\npositive_days.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "very_positive_days = new_df[(new_df.close - new_df.open) > 4]\nvery_positive_days.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Creating new columns",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To create a new column, simply assign values to it.  Think of the columns as a dictionary:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df['profit'] = (new_df.open < new_df.close)\nnew_df.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's give each row a ``gain`` value as a categorical variable:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "for idx, row in new_df.iterrows():\n    if row.open > row.close:\n        new_df.loc[idx,'gain']='negative'\n    elif (row.close - row.open) < 1:\n        new_df.loc[idx,'gain']='small_gain'\n    elif (row.close - row.open) < 3:\n        new_df.loc[idx,'gain']='medium_gain'\n    else:\n        new_df.loc[idx,'gain']='large_gain'\nnew_df.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Here is another, more \"functional\", way to accomplish the same thing.\n\nDefine a function that classifies rows, and **`apply`** it to each row.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "def namerow(row):\n    if row.open > row.close:\n        return 'negative'\n    elif (row.close - row.open) < 1:\n        return 'small_gain'\n    elif (row.close - row.open) < 3:\n        return 'medium_gain'\n    else:\n        return 'large_gain'\n\nnew_df['test_column'] = new_df.apply(namerow, axis = 1)\n",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "new_df.head()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "OK, point made, let's get rid of that extraneous `test_column`:",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "new_df.drop('test_column', axis = 1)",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Grouping",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "An **extremely** powerful DataFrame method is **`groupby()`**. \n\nThis is entirely analagous to **`GROUP BY`** in SQL.\n\nIt will group the rows of a DataFrame by the values in one (or more) columns, and let you iterate through each group.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Here we will look at the average gain among the  categories of gains (negative, small, medium and large) we defined above and stored in column `gain`.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "gain_groups = new_df.groupby('gain')",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Essentially, **`gain_groups`** behaves like a dictionary:\n* the keys are the unique values found in the `gain` column, and \n* the values are DataFrames that contain only the rows having the corresponding unique values.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "for gain, gain_data in gain_groups:\n    print(gain)\n    print(gain_data.head())\n    print('=============================')",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for gain, gain_data in new_df.groupby(\"gain\"):\n    print('The average closing value for the {} group is {}'.format(gain,\n                                                           gain_data.close.mean()))",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Other Pandas Classes\n\nA DataFrame is essentially an annotated 2-D array.\n\nPandas also has annotated versions of 1-D and 3-D arrays.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "A 1-D array in Pandas is called a `Series`.\n\nA 3-D array in Pandas is created using a ``MultiIndex``.\n\nTo use these, read the documentation!",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Comparing multiple stocks",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "As a last task, we will use the experience we obtained so far -- and learn some new things -- in order to compare the performance of different stocks we obtained from Yahoo finance.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# stocks = ['ORCL', 'TSLA', 'IBM', 'AAPL', 'MSFT']\n# attr = 'Close'\n# stock_df = web.DataReader(stocks, \n#                     data_source,                               \n#                     start=datetime(2021, 1, 1), \n#                     end=datetime(2021, 12, 31))[attr]\n# stock_df.head()\n\n# stock_df.to_csv('yahoo_multiple_stocks_data.csv')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "stock_df = pd.read_csv('yahoo_multiple_stocks_data.csv')\nstock_df.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "stock_df.plot();",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Next, we will calculate returns over a period of length $T,$ defined as:\n\n$$ r(t) = \\frac{f(t)-f(t-T)}{f(t)} $$",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The returns can be computed with a simple DataFrame method **`pct_change()`**.  Note that for the first $T$ timesteps, this value is not defined (of course):",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "rets = stock_df.loc[:, (\"ORCL\", \"TSLA\", \"IBM\", \"AAPL\", \"MSFT\")].pct_change(30)\nrets.iloc[25:35]",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we'll plot the timeseries of the returns of the different stocks.\n\nNotice that the `NaN` values are gracefully dropped by the plotting function.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "rets.plot();",
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.scatter(rets.MSFT, rets.AAPL)\nplt.xlabel('MSFT 30-day returns')\nplt.ylabel('AAPL 30-day returns');",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "There appears to be some (fairly strong) correlation between the movement of MSFT and AAPL stocks.  Let's measure this.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The correlation coefficient between variables $X$ and $Y$ is defined as follows:\n\n$$ \\text{Corr}(X,Y) = \\frac{E\\left[(X-\\mu_X)(Y-\\mu_Y)\\right]}{\\sigma_X\\sigma_Y} $$\n\nPandas provides a dataframe method to compute the correlation coefficient of all pairs of columns: **`corr()`**.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "rets.corr()",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "It takes a bit of time to examine that table and draw conclusions.  \n\nTo speed that process up it helps to visualize the table.\n\nWe will learn more about visualization later, but for now this is a simple example.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "sns.heatmap(rets.corr(), annot=True);",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Finally, it is important to know that the plotting performed by Pandas is just a layer on top of `matplotlib` (i.e., the `plt` package).  \n\nSo Panda's plots can (and often should) be replaced or improved by using additional functions from `matplotlib`.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "For example, suppose we want to know both the returns as well as the standard deviation of the returns of a stock (i.e., its risk).  \n\nHere is visualization of the result of such an analysis, and we construct the plot using only functions from `matplotlib`.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# plt.scatter(rets.mean(), rets.std());\nplt.xlabel('Expected returns')\nplt.ylabel('Standard Deviation (Risk)')\nplt.xlim([-.05,.1])\nplt.ylim([0,.3])\nfor label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n    plt.annotate(\n        label, \n        xy = (x, y), xytext = (30, -30),\n        textcoords = 'offset points', ha = 'right', va = 'bottom',\n        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To understand what these functions are doing, (especially the `annotate` function), you will need to consult the online documentation for matplotlib.  Just use Google to find it.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    }
  ]
}